---
title: "ST_2_spatial"
author: "Sean Swift"
date: "January 30, 2020"
output:
  html_document:
        toc: true
        toc_depth: 4
        number_sections: true
---


# Description
ST_Spatial focuses on importing raster data, some visualization of the rasters, and extraction of rater data by sampling location.
Raster data is then added to the sample metadata for downstream analyses. 

# Pulling out spatial data from rasters
We have GPS coordinates for each sample. There are freely available raster data sets for environmental variables (elevation, rainfall, temp).
Using the sample coordinates, pull out these environmental variables and join them to the sample metadata
```{r libraries echo = FALSE}
library(raster)
library(ggplot2)
library(dplyr)
library(tidyr)
library(rgdal)
library(geosphere)
library(vegan)
```

## Set up
Import sample and run metadata

```{r import}
#read in data

ST_16S <- readRDS("data/processed/cleaned/ST_16S.rds")

## check that lat/long is in good shape
range(ST_16S$metadata$lat, na.rm = T)
range(ST_16S$metadata$long, na.rm = T)


## select just samples that were collected in the field and have lat long (no controls)
field_meta <- ST_16S$metadata %>%
                filter(!is.na(lat) & !is.na(long))
field_meta <- field_meta %>%
  filter(sample_type != "PlantShoot")


## read in metadata for MS samples
MS_meta <-read.csv("data/raw/sample/MS_samples_waimea_supertransect - Full Metadata Waimea_Supertransect.csv")

```

### Rainfall

```{r rainfall}
# rasters are yearly averages, and can be
# found at rainfall atlas of hawaii and evapotranspiration hawaii
# http://rainfall.geography.hawaii.edu/rainfall.html
#Extract data from rasters using sampling coordinates

set_proj <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84"


#use annual rainfall txt file to make raster

oahu_rainfall <- raster("data/raw/spatial/rfgrid_mm_oahu_ann.txt", crs = set_proj)
oahu_rainfall

# extract values
field_meta$rainfall <-  raster::extract(x = oahu_rainfall,
                        y = field_meta[c("long","lat")],
                        df = TRUE)[[2]]
MS_meta$rainfall <-  raster::extract(x = oahu_rainfall,
                        y = MS_meta[c("long","lat")],
                        df = TRUE)[[2]]


#makes raster map of oahu
tiff(filename = "outputs/figures/rainfall_sites.tiff", height = 7, width =  7, res = 300, units = "in")
plot(oahu_rainfall, main=" Estimated Annual Rainfall for Oahu (m)")
points(x=field_meta$long, y=field_meta$lat, pch=20, col="black", cex=1)
points(x=field_meta$long, y=field_meta$lat, pch=20, col="white", cex=0.4)
dev.off()

```

### Elevation

```{r elevation}
# source: http://www.soest.hawaii.edu/coasts/data/hawaii/dem.html
#  Code to correct project for raw raster. Takes a lot of resources to run. 
 oahu_elevation <- raster("data/raw/spatial/oahu_dem/w001001.adf")
 oahu_elevation <- projectRaster(oahu_elevation, crs = set_proj)
# saveRDS(oahu_elevation,"data/interim/oahu_elev_raster.RDS")

# oahu_elevation <- readRDS("data/interim/oahu_elev_raster.RDS")
oahu_elevation

# extract values
field_meta$elevation <-  raster::extract(x = oahu_elevation,
                        y = field_meta[c("long","lat")],
                        df = TRUE)[[2]]
MS_meta$elevation <-  raster::extract(x = oahu_elevation,
                        y = MS_meta[c("long","lat")],
                        df = TRUE)[[2]]

plot(oahu_elevation)
points(x=field_meta$long, y=field_meta$lat, pch=20, col="black", cex=1)
points(x=field_meta$long, y=field_meta$lat, pch=20, col="white", cex=0.4)

```


### C-CAP
C-CAP is very high resolution and takes a long time to proccess.
Until this is deemed immediately useful I will wait to include it.

```{r}

# ccap <- raster("data/raw/spatial/CCAP/hi_oahu_2011_ccap_hr_land_cover20140619.img")
# 
# # need to change projection, but process is taking a long time
# 
# #ccap <- projectRaster(ccap, crs = set_proj)
# 
# ccap
# 
# 
# plot(ccap)

```

### Distance from shore for each site
Anthony suggests organizing the gradient by distance from shore, which varies colinearly with precipitation, elevation, etc.

```{r distance shore}
# Choose arbitrary point on shore

shore <- c(-158.063539,21.640629)

# Calculate distance for each sample

field_meta$shore_dist <- geosphere::distGeo(shore, field_meta[c("long","lat")])
MS_meta$shore_dist <- geosphere::distGeo(shore, MS_meta[c("long","lat")])

# Show colinearity of rainfall, elevation, distance from shore

# total range
max(field_meta$shore_dist) - min(field_meta$shore_dist)

plot(
  field_meta$site_order,
  field_meta$shore_dist,
  col = "red",
  pch = 20,
  xlab = "Sampling Site",
  ylab = "Value",
  main = "Variation in Distance, Rainfall, and Elevation"
  )
  
  points(field_meta$site_order,
  field_meta$rainfall,
  col = "blue",
  pch = 20)
  
  points(field_meta$site_order,
  field_meta$elevation,
  col = "green",
  pch = 20)
  
  legend(
  x = 0,
  y = 10000,
  c("Distance from shore", "Rainfall", "Elevation"),
  col = c("red", "blue", "green"),
  pch = 20
  )

# plot just rainfall against shore distance
transect_meta <- field_meta[field_meta$habitat != "Marine",]
 
tiff("outputs/figures/rainfall_vs_shore_dist.tiff", height = 7, width =  7, res = 300, units = "in")
par(mar = c(5.1,4.8,4.1,2.1))
plot(
  transect_meta$shore_dist,
  transect_meta$rainfall,
  col = "darkblue",
  pch = 16,
  cex = 1.3,
  xlab = "Distance From Shore (m)",
  ylab = "Mean Annual Precipitation (mm)",
  cex.lab = 1.8
  )


dev.off()

```

### Update metadata to include spatial data and remove suspect sample

```{r}
# add lab samples back in
lab_samples <- ST_16S$metadata[!(ST_16S$metadata$id %in% field_meta$id),]

# set all spatial data to NA
lab_samples$rainfall   <- NA
lab_samples$elevation  <- NA
lab_samples$shore_dist <- NA


# check that columns match
all_equal(colnames(field_meta), colnames(lab_samples))

# bind together
metadata <- rbind(field_meta,lab_samples)
metadata <- metadata[ match(ST_16S$metadata$id, metadata$id), ]

# add in correct levels for transect names
metadata$transect_name %>% unique
transect_levels <- c(
  "Marine" ,
  "STEstuary",
  "STGardens",
  "STFalls",
  "STAboveFalls",
  "STDrumRoadMakai",
  "STDrumRoadMauka",
  "STSummit",
  "NA"
  )

  
metadata$transect_name <- factor(metadata$transect_name, levels = transect_levels )

# check that all the samples made it in the right order
all_equal(metadata$id, ST_16S$metadata$id)

# Remove suspect sample 105464, which should be sediment, but clusters with mosquito samples
metadata <- metadata[metadata$sample_id != 105464,]
ST_16S$abundance <- ST_16S$abundance[ST_16S$abundance$Group != 105464,]






```

## Generate unified barcode
MS and DNA samples sometimes have different barcodes.
Rather than change MS sample names, easier to change microbe names, I think. 


```{r}
# Read in key file
bcode_key <- read.csv("data/raw/sample/Waimea_SuperTransect_SampleSheet - AllSite_AllSamples_Accession.csv")

# generate key column to match DNA and MS samples
bcode_key$unique_site <- paste(bcode_key$Sample,
                               bcode_key$Transect,
                               bcode_key$Site, 
                               bcode_key$Replicate,
                               bcode_key$Metadata, sep = "_")

bcode_key <- pivot_wider(bcode_key, id_cols = unique_site, values_from = Barcode, names_from = Analysis, names_repair = "minimal")

# join the MS barcodes onto the DNA barcodes by DNA barcode
metadata_add <- left_join(metadata, bcode_key, by = c("sample_barcode" = "DNA"))
metadata_add <- metadata_add %>% rename(MS_barcode = MS)

# add in marine MS barcodes (identical to DNA barcodes)
metadata_add$MS_barcode[metadata_add$transect_name %in% "Marine"] <- metadata_add$sample_barcode[metadata_add$transect_name %in% "Marine"]

# summit water samples were sampled twice
# add the same MS barcode to both samples

summit_originals <- c(2217,
                      2225,
                      2233,
                      2241,
                      2249,
                      2257,
                      2265,
                      2273,
                      2281)

summit_duplicates <- c (3442,
                        3431,
                        3432,
                        3433,
                        3434,
                        3435,
                        3436,
                        3437,
                        3438)
# Probably a more succinct way to do this
# for each duplicate summit water sample, add the same MS barcode as the original

for( i in seq_along(summit_originals)){
  metadata_add$MS_barcode[metadata_add$sample_barcode %in% summit_duplicates[i]] <- metadata_add$MS_barcode[metadata_add$sample_barcode %in% summit_originals[i]]
}

# Check remaining "NA" MS barcodes
# should be mostly controls and a couple mosquito/drosophila
metadata_add$sample_type[is.na(metadata_add$MS_barcode)]

# update ST_16S list of dataframes
ST_16S$metadata <- metadata_add

# write to an r file
saveRDS(ST_16S,"data/processed/cleaned/ST_16S_spatial.rds")

# write to tsv files for MS analysis
write.table(ST_16S$abundance, "data/processed/ST_16S_abundance.tsv",sep = "\t")
write.table(ST_16S$taxonomy, "data/processed/ST_16S_taxonomy.tsv",sep = "\t")
write.table(ST_16S$metadata, "data/processed/ST_16S_taxonomy.tsv",sep = "\t")

# Add the same key columns to the MS metadata
bcodes <-metadata_add[c("sample_barcode","MS_barcode")]
colnames(bcodes) <- c("DNA_barcode","MS_barcode")

# drop the summit originals samples (otherwise messes up 1 to 1 relationship)
# these samples are also dropped for microbiome analyses later on

bcodes <- bcodes[bcodes$DNA_barcode]


MS_meta_add <- MS_meta %>% left_join(bcodes, by = c("sample_barcode" = "MS_barcode"))
MS_meta_add[is.na(MS_meta_add$DNA_barcode),] %>% group_by(sample_type) %>% summarize ( n())

# write out MS metadata as a csv to re-upload to google drive
write.csv(MS_meta_add, "data/processed/cleaned/Full Metadata Waimea_Supertransect.csv", row.names = F)
```

